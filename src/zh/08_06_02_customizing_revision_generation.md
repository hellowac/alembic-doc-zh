# Customizing Revision Generation

[command.revision()]: ../en/commands.html#alembic.command.revision
[MigrateOperation]: ../en/operations.html#alembic.operations.ops.MigrateOperation
[MigrationScript]: ../en/operations.html#alembic.operations.ops.MigrationScript
[render_python_code()]: #alembic.autogenerate.render_python_code
[EnvironmentContext.configure.process_revision_directives]: ../en/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.process_revision_directives
[Don’t Generate Empty Migrations with Autogenerate]: ../en/../cookbook.html#cookbook-no-empty-migrations
[Don’t emit DROP INDEX when the table is to be dropped as well]: ../en/../cookbook.html#cookbook-dont-emit-drop-index
[Apply Custom Sorting to Table Columns within CREATE TABLE]: ../en/../cookbook.html#cookbook-custom-sorting-create-table
[Rewriter]: #alembic.autogenerate.rewriter.Rewriter
[ops.AddColumnOp]: ../en/operations.html#alembic.operations.ops.AddColumnOp
[ops.MigrationScript]: ../en/operations.html#alembic.operations.ops.MigrationScript
[AddColumn]: ../en/ddl.html#alembic.ddl.base.AddColumn
[MigrationContext]: ../en/runtime.html#alembic.runtime.migration.MigrationContext
[Fine-Grained Autogenerate Generation with Rewriters]: #autogen-rewriter
[Engine]: https://docs.sqlalchemy.org/en/14/core/connections.html#sqlalchemy.engine.Engine
[MigrationContext.run_migrations()]: ../en/runtime.html#alembic.runtime.migration.MigrationContext.run_migrations
[upgrade_token]: ../en/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.upgrade_token
[downgrade_token]: ../en/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.downgrade_token
[UpgradeOps]: ../en/operations.html#alembic.operations.ops.UpgradeOps
[DowngradeOps]: ../en/operations.html#alembic.operations.ops.DowngradeOps
[MigrationScript.upgrade_ops_list]: ../en/operations.html#alembic.operations.ops.MigrationScript.upgrade_ops_list
[MigrationScript.downgrade_ops_list]: ../en/operations.html#alembic.operations.ops.MigrationScript.downgrade_ops_list
[str]: https://docs.python.org/3/library/stdtypes.html#str
[bool]: https://docs.python.org/3/library/functions.html#bool
[None]: https://docs.python.org/3/library/constants.html#None

The `alembic revision` command, also available programmatically via **[command.revision()]**, essentially produces a single migration script after being run. Whether or not the `--autogenerate` option was specified basically determines if this script is a blank revision script with empty `upgrade()` and `downgrade()` functions, or was produced with alembic operation directives as the result of autogenerate.

In either case, the system creates a full plan of what is to be done in the form of a **[MigrateOperation]** structure, which is then used to produce the script.

For example, suppose we ran `alembic revision --autogenerate`, and the end result was that it produced a new revision `'eced083f5df'` with the following contents:

```python
"""create the organization table."""

# revision identifiers, used by Alembic.
revision = 'eced083f5df'
down_revision = 'beafc7d709f'

from alembic import op
import sqlalchemy as sa


def upgrade():
    op.create_table(
        'organization',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('name', sa.String(50), nullable=False)
    )
    op.add_column(
        'user',
        sa.Column('organization_id', sa.Integer())
    )
    op.create_foreign_key(
        'org_fk', 'user', 'organization', ['organization_id'], ['id']
    )

def downgrade():
    op.drop_constraint('org_fk', 'user')
    op.drop_column('user', 'organization_id')
    op.drop_table('organization')
```

The above script is generated by a **[MigrateOperation]** structure that looks like this:

```python
from alembic.operations import ops
import sqlalchemy as sa

migration_script = ops.MigrationScript(
    'eced083f5df',
    ops.UpgradeOps(
        ops=[
            ops.CreateTableOp(
                'organization',
                [
                    sa.Column('id', sa.Integer(), primary_key=True),
                    sa.Column('name', sa.String(50), nullable=False)
                ]
            ),
            ops.ModifyTableOps(
                'user',
                ops=[
                    ops.AddColumnOp(
                        'user',
                        sa.Column('organization_id', sa.Integer())
                    ),
                    ops.CreateForeignKeyOp(
                        'org_fk', 'user', 'organization',
                        ['organization_id'], ['id']
                    )
                ]
            )
        ]
    ),
    ops.DowngradeOps(
        ops=[
            ops.ModifyTableOps(
                'user',
                ops=[
                    ops.DropConstraintOp('org_fk', 'user'),
                    ops.DropColumnOp('user', 'organization_id')
                ]
            ),
            ops.DropTableOp('organization')
        ]
    ),
    message='create the organization table.'
)
```

When we deal with a **[MigrationScript]** structure, we can render the upgrade/downgrade sections into strings for debugging purposes using the **[render_python_code()]** helper function:

```python
from alembic.autogenerate import render_python_code
print(render_python_code(migration_script.upgrade_ops))
```

Renders:

```python
### commands auto generated by Alembic - please adjust! ###
    op.create_table('organization',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=50), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.add_column('user', sa.Column('organization_id', sa.Integer(), nullable=True))
    op.create_foreign_key('org_fk', 'user', 'organization', ['organization_id'], ['id'])
    ### end Alembic commands ###
```

Given that structures like the above are used to generate new revision files, and that we’d like to be able to alter these as they are created, we then need a system to access this structure when the **[command.revision()]** command is used. The **[EnvironmentContext.configure.process_revision_directives]** parameter gives us a way to alter this. This is a function that is passed the above structure as generated by Alembic, giving us a chance to alter it. For example, if we wanted to put all the “upgrade” operations into a certain branch, and we wanted our script to not have any “downgrade” operations at all, we could build an extension as follows, illustrated within an `env.py` script:

```python
def process_revision_directives(context, revision, directives):
    script = directives[0]

    # set specific branch
    script.head = "mybranch@head"

    # erase downgrade operations
    script.downgrade_ops.ops[:] = []

# ...

def run_migrations_online():

    # ...
    with engine.connect() as connection:

        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            process_revision_directives=process_revision_directives)

        with context.begin_transaction():
            context.run_migrations()
```

Above, the `directives` argument is a Python list. We may alter the given structure within this list in-place, or replace it with a new structure consisting of zero or more **[MigrationScript]** `directives`. The **[command.revision()]** command will then produce scripts corresponding to whatever is in this list.

> **See also:** More examples of using [EnvironmentContext.configure.process_revision_directives]
>
> * **[Don’t Generate Empty Migrations with Autogenerate]**
> * **[Don’t emit DROP INDEX when the table is to be dropped as well]**
> * **[Apply Custom Sorting to Table Columns within CREATE TABLE]**

* alembic.autogenerate.**render_python_code**(*up_or_down_op*:  UpgradeOps, *sqlalchemy_module_prefix*:  [str] = 'sa.', *alembic_module_prefix*:  [str] = 'op.', *render_as_batch*:  [bool] = False, *imports*:  Tuple\[[str], ...\] = (), *render_item*:  [None] = [None], *migration_context*:  Optional\[MigrationContext\] = None) → str

    Render Python code given an **[UpgradeOps]** or **[DowngradeOps]** object.

    This is a convenience function that can be used to test the autogenerate output of a user-defined **[MigrationScript]** structure.

## Fine-Grained Autogenerate Generation with Rewriters

**带有重写器的细粒度自动生成**

The preceding example illustrated how we can make a simple change to the structure of the operation directives to produce new autogenerate output. For the case where we want to affect very specific parts of the autogenerate stream, we can make a function for **[EnvironmentContext.configure.process_revision_directives]** which traverses through the whole **[MigrationScript]** structure, locates the elements we care about and modifies them in-place as needed. However, to reduce the boilerplate associated with this task, we can use the **[Rewriter]** object to make this easier. **[Rewriter]** gives us an object that we can pass directly to **[EnvironmentContext.configure.process_revision_directives]** which we can also attach handler functions onto, keyed to specific types of constructs.

Below is an example where we rewrite **[ops.AddColumnOp]** directives; based on whether or not the new column is “nullable”, we either return the existing directive, or we return the existing directive with the nullable flag changed, inside of a list with a second directive to alter the nullable flag in a second step:

```python
# ... fragmented env.py script ....

from alembic.autogenerate import rewriter
from alembic.operations import ops

writer = rewriter.Rewriter()

@writer.rewrites(ops.AddColumnOp)
def add_column(context, revision, op):
    if op.column.nullable:
        return op
    else:
        op.column.nullable = True
        return [
            op,
            ops.AlterColumnOp(
                op.table_name,
                op.column.name,
                modify_nullable=False,
                existing_type=op.column.type,
            )
        ]

# ... later ...

def run_migrations_online():
    # ...

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            process_revision_directives=writer
        )

        with context.begin_transaction():
            context.run_migrations()
```

Above, in a full **[ops.MigrationScript]** structure, the **[AddColumn]** directives would be present within the paths `MigrationScript->UpgradeOps->ModifyTableOps` and `MigrationScript->DowngradeOps->ModifyTableOps`. The **[Rewriter]** handles traversing into these structures as well as rewriting them as needed so that we only need to code for the specific object we care about.

* *class* alembic.autogenerate.rewriter.**Rewriter**

    A helper object that allows easy ‘rewriting’ of ops streams.

    The **[Rewriter]** object is intended to be passed along to the **[EnvironmentContext.configure.process_revision_directives]** parameter in an `env.py` script. Once constructed, any number of “rewrites” functions can be associated with it, which will be given the opportunity to modify the structure without having to have explicit knowledge of the overall structure.

    The function is passed the **[MigrationContext]** object and `revision` tuple that are passed to the `Environment Context.configure.process_revision_directives` function normally, and the third argument is an individual directive of the type noted in the decorator. The function has the choice of returning a single op directive, which normally can be the directive that was actually passed, or a new directive to replace it, or a list of zero or more directives to replace it.

    > **See also:** [Fine-Grained Autogenerate Generation with Rewriters - usage example]

  * **chain**(other: [alembic.autogenerate.rewriter.Rewriter]) → [alembic.autogenerate.rewriter.Rewriter]

    Produce a “chain” of this **[Rewriter]** to another.

    This allows two rewriters to operate serially on a stream, e.g.:

    ```python
    writer1 = autogenerate.Rewriter()
    writer2 = autogenerate.Rewriter()

    @writer1.rewrites(ops.AddColumnOp)
    def add_column_nullable(context, revision, op):
        op.column.nullable = True
        return op

    @writer2.rewrites(ops.AddColumnOp)
    def add_column_idx(context, revision, op):
        idx_op = ops.CreateIndexOp(
            'ixc', op.table_name, [op.column.name])
        return [
            op,
            idx_op
        ]

    writer = writer1.chain(writer2)
    ```

    **Parameters:** ***other*** – a **[Rewriter]** instance

    **Returns:** a new **[Rewriter]** that will run the operations of this writer, then the “other” writer, in succession.

  * **rewrites**(operator: Union\[Type\[AddColumnOp\], Type\[MigrateOperation\], Type\[AlterColumnOp\], Type\[CreateTableOp\], Type\[ModifyTableOps\]\]) → Callable

    Register a function as rewriter for a given type.

    The function should receive three arguments, which are the **[MigrationContext]**, a `revision` tuple, and an op directive of the type indicated. E.g.:

    ```python
    @writer1.rewrites(ops.AddColumnOp)
    def add_column_nullable(context, revision, op):
        op.column.nullable = True
        return op
    ```

## Revision Generation with Multiple Engines / run_migrations() calls

A lesser-used technique which allows autogenerated migrations to run against multiple database backends at once, generating changes into a single migration script, is illustrated in the provided `multidb` template. This template features a special `env.py` which iterates through multiple **[Engine]** instances and calls upon **[MigrationContext.run_migrations()]** for each:

```python
for name, rec in engines.items():
    logger.info("Migrating database %s" % name)
    context.configure(
        connection=rec['connection'],
        upgrade_token="%s_upgrades" % name,
        downgrade_token="%s_downgrades" % name,
        target_metadata=target_metadata.get(name)
    )
    context.run_migrations(engine_name=name)
```

Above, **[MigrationContext.run_migrations()]** is run multiple times, once for each engine. Within the context of autogeneration, each time the method is called the **[upgrade_token]** and **[downgrade_token]** parameters are changed, so that the collection of template variables gains distinct entries for each engine, which are then referred to explicitly within `script.py.mako`.

In terms of the **[EnvironmentContext.configure.process_revision_directives]** hook, the behavior here is that the `process_revision_directives` hook is invoked multiple times, once for each call to context.run_migrations(). This means that if a multi-run_migrations() approach is to be combined with the `process_revision_directives` hook, care must be taken to use the hook appropriately.

The first point to note is that when a **second** call to `run_migrations()` occurs, the `.upgrade_ops` and `.downgrade_ops` attributes are **converted into Python lists**, and new **[UpgradeOps]** and **[DowngradeOps]** objects are appended to these lists. Each **[UpgradeOps]** and **[DowngradeOps]** object maintains an `.upgrade_token` and a `.downgrade_token` attribute respectively, which serves to render their contents into the appropriate template token.

For example, a multi-engine run that has the engine names `engine1` and `engine2` will generate tokens of `engine1_upgrades`, `engine1_downgrades`, `engine2_upgrades` and `engine2_downgrades` as it runs. The resulting migration structure would look like this:

```python
from alembic.operations import ops
import sqlalchemy as sa

migration_script = ops.MigrationScript(
    'eced083f5df',
    [
        ops.UpgradeOps(
            ops=[
                # upgrade operations for "engine1"
            ],
            upgrade_token="engine1_upgrades"
        ),
        ops.UpgradeOps(
            ops=[
                # upgrade operations for "engine2"
            ],
            upgrade_token="engine2_upgrades"
        ),
    ],
    [
        ops.DowngradeOps(
            ops=[
                # downgrade operations for "engine1"
            ],
            downgrade_token="engine1_downgrades"
        ),
        ops.DowngradeOps(
            ops=[
                # downgrade operations for "engine2"
            ],
            downgrade_token="engine2_downgrades"
        )
    ],
    message='migration message'
)
```

Given the above, the following guidelines should be considered when the `env.py` script calls upon **[MigrationContext.run_migrations()]** multiple times when running autogenerate:

* If the `process_revision_directives` hook aims to **add elements based on inspection of the current database / connection**, it should do its operation on each iteration. This is so that each time the hook runs, the database is available.
* Alternatively, if the `process_revision_directives` hook aims to **modify the list of migration directives in place**, this should be called only on the last iteration. This is so that the hook isn’t being given an ever-growing structure each time which it has already modified previously.
* The **[Rewriter]** object, if used, should be called **only on the last iteration**, because it will always deliver all directives every time, so again to avoid double/triple/etc. processing of directives it should be called only when the structure is complete.
* The **[MigrationScript.upgrade_ops_list]** and **[MigrationScript.downgrade_ops_list]** attributes should be consulted when referring to the collection of **[UpgradeOps]** and **[DowngradeOps]** objects.
